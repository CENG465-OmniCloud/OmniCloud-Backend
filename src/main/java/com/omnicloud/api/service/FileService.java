package com.omnicloud.api.service;

import com.omnicloud.api.config.MinioConfig;
import com.omnicloud.api.model.*;
import com.omnicloud.api.repository.FileMetadataRepository;
import com.omnicloud.api.repository.StorageProviderRepository;
import jakarta.transaction.Transactional;
import org.springframework.stereotype.Service;
import org.springframework.web.multipart.MultipartFile;

import javax.crypto.SecretKey;
import javax.crypto.spec.IvParameterSpec;
import java.io.IOException;
import java.time.LocalDateTime;
import java.util.ArrayList;
import java.util.Base64;
import java.util.List;
import java.util.UUID;
import java.util.concurrent.CompletableFuture;
import java.util.stream.Collectors;

@Service
public class FileService {

    private final FileMetadataRepository repository;
    private final EncryptionService encryptionService;
    private final ErasureService erasureService;
    private final StorageService storageService;
    private final StorageProviderRepository providerRepository;

    // Sabit 6 Node, 4 Data, 2 Parity
    private static final int DATA_SHARDS = 4;

    public FileService(FileMetadataRepository repository,
                       EncryptionService encryptionService,
                       ErasureService erasureService,
                       StorageService storageService,
                       StorageProviderRepository providerRepository) {
        this.repository = repository;
        this.encryptionService = encryptionService;
        this.erasureService = erasureService;
        this.storageService = storageService;
        this.providerRepository = providerRepository;
    }

    @Transactional
    public FileMetadata uploadFile(MultipartFile file) throws Exception {
        // 0. Fetch Providers (We need to know how many exist to calculate locations)
        List<StorageProvider> providers = providerRepository.findAll();
        if (providers.isEmpty()) {
            throw new RuntimeException("No Storage Providers found! Cannot upload file.");
        }

        // 1. Generate Security Keys
        SecretKey key = encryptionService.generateKey();
        IvParameterSpec iv = encryptionService.generateIv();

        // ADIM A: √ñnce Metadata nesnesini olu≈ütur
        FileMetadata metadata = FileMetadata.builder()
                .filename(file.getOriginalFilename())
                .fileSize(file.getSize())
                .uploadDate(LocalDateTime.now())
                .encryptionKey(encryptionService.keyToString(key))
                .iv(Base64.getEncoder().encodeToString(iv.getIV()))
                .build();

        // ADIM B: ƒ∞lk Kayƒ±t -> Bu i≈ülem nesneye bir UUID atar.
        metadata = repository.save(metadata);
        String fileId = metadata.getId().toString();

        // 2. Read & Encrypt
        byte[] originalBytes = file.getBytes();
        byte[] encryptedBytes = encryptionService.encrypt(originalBytes, key, iv);

        // 3. Split (Erasure Coding)
        List<Shard> shards = erasureService.encode(encryptedBytes);

        // 4. Upload to (StorageService handles the distribution)
        storageService.uploadShards(shards, fileId);

        // 5. Shard Metadata'larƒ±nƒ± ekle
        for (Shard s : shards) {
            // Replicate Round-Robin Logic to find which bucket this shard went to
            // Logic: ShardIndex % ProviderCount
            int providerIndex = s.getIndex() % providers.size();
            StorageProvider usedProvider = providers.get(providerIndex);


            ShardMetadata sm = ShardMetadata.builder()
                    .shardIndex(s.getIndex())
                    .minioBucketName(usedProvider.getBucketName()) //dynamic bucket name
                    .status(ShardStatus.ALIVE)
                    .build();
            metadata.addShard(sm);
        }

        // ADIM C: ƒ∞kinci Kayƒ±t -> Shard bilgileriyle beraber g√ºncelliyoruz.
        return repository.save(metadata);
    }

    public byte[] downloadFile(UUID fileId) throws Exception {
        // 1. Fetch Metadata
        FileMetadata metadata = repository.findById(fileId)
                .orElseThrow(() -> new RuntimeException("File not found"));

        // 2. Parallel Fetch from MinIO
        List<CompletableFuture<Shard>> futures = new ArrayList<>();

        for (ShardMetadata sm : metadata.getShards()) {
            CompletableFuture<Shard> future = CompletableFuture.supplyAsync(() -> {
                String objectName = fileId.toString() + "/" + sm.getShardIndex();
                byte[] data = storageService.downloadShard(sm.getMinioBucketName(), objectName, sm.getShardIndex());

                if (data == null) return null; // Node was down
                return new Shard(sm.getShardIndex(), data);
            });
            futures.add(future);
        }

        // Wait for all attempts
        CompletableFuture.allOf(futures.toArray(new CompletableFuture[0])).join();

        // 3. Collect Valid Shards
        List<Shard> downloadedShards = futures.stream()
                .map(CompletableFuture::join)
                .filter(shard -> shard != null) // Filter out failed downloads
                .collect(Collectors.toList());

        if (downloadedShards.size() < DATA_SHARDS) {
            throw new RuntimeException("CRITICAL DATA LOSS: Only retrieved " + downloadedShards.size() + "/6 shards. Need 4.");
        }

        // 4. Reconstruct (Erasure Decode)
        // Therefore: shardSize * DATA_SHARDS gives us the exact encrypted size.
        int shardSize = downloadedShards.get(0).getData().length;
        int totalEncryptedSize = shardSize * DATA_SHARDS;

        byte[] recoveredEncrypted = erasureService.decode(downloadedShards, totalEncryptedSize);

        // 5. Decrypt
        SecretKey key = encryptionService.stringToKey(metadata.getEncryptionKey());
        IvParameterSpec iv = new IvParameterSpec(Base64.getDecoder().decode(metadata.getIv()));

        byte[] decryptedData = encryptionService.decrypt(recoveredEncrypted, key, iv);

        // 6. Trim Padding (AES Padding might add bytes, Stream logic handles this usually)
        return decryptedData;
    }
    public String repairFile(UUID fileId) throws Exception {
        System.out.println("üîß Starting Repair Process for File ID: " + fileId);

        // 1. Dosyayƒ± mevcut (saƒülam) par√ßalardan indir ve RAM'de birle≈ütir
        // (Eƒüer yeterli par√ßa yoksa downloadFile zaten hata fƒ±rlatƒ±r)
        byte[] recoveredFile = downloadFile(fileId);

        if (recoveredFile == null) {
            throw new RuntimeException("File recovery failed. Not enough shards available.");
        }
        System.out.println("‚úÖ File reconstructed in memory from surviving shards.");

        // 2. Metadata'yƒ± √ßek (≈ûifreleme anahtarlarƒ± i√ßin)
        FileMetadata metadata = repository.findById(fileId).orElseThrow();
        SecretKey key = encryptionService.stringToKey(metadata.getEncryptionKey());
        IvParameterSpec iv = new IvParameterSpec(Base64.getDecoder().decode(metadata.getIv()));

        // 3. Dosyayƒ± tekrar ≈ûifrele ve Par√ßala (Tƒ±pkƒ± ilk upload gibi)
        // √á√ºnk√º MinIO'ya ≈üifreli par√ßa y√ºklememiz lazƒ±m.
        byte[] encryptedBytes = encryptionService.encrypt(recoveredFile, key, iv);
        List<Shard> allShards = erasureService.encode(encryptedBytes);

        //Fetch providers for cheking buckets
        List<StorageProvider> providers = providerRepository.findAll();

        // 4. Hangi par√ßalarƒ±n eksik olduƒüunu bul ve sadece onlarƒ± y√ºkle
        int repairedCount = 0;

        for (Shard shard : allShards) {
            // Calculate which provider owns this shard
            int providerIndex = shard.getIndex() % providers.size();
            String correctBucket = providers.get(providerIndex).getBucketName();
            // MinIO'da bu par√ßa var mƒ± kontrol et
            byte[] existingData = storageService.downloadShard(
                    correctBucket,
                    fileId.toString() + "/" + shard.getIndex(),
                    shard.getIndex()
            );

            // Eƒüer null d√∂nd√ºyse, o sunucu bo≈ü demektir (veya yeni a√ßƒ±lmƒ±≈ütƒ±r)
            if (existingData == null) {
                System.out.println("‚ö†Ô∏è Missing Shard detected: Index " + shard.getIndex());

                // Sadece bu par√ßayƒ± i√ßeren tek elemanlƒ± bir liste yapƒ±p g√∂nderiyoruz
                List<Shard> shardToRestore = new ArrayList<>();
                shardToRestore.add(shard);

                storageService.uploadShards(shardToRestore, fileId.toString());
                repairedCount++;
                System.out.println("‚ôªÔ∏è Repaired/Uploaded Shard " + shard.getIndex());
            }
        }

        if (repairedCount == 0) {
            return "System Healthy: No shards were missing.";
        } else {
            return "SUCCESS: Restored " + repairedCount + " missing shards.";
        }
    }

    @Transactional
    public void deleteFile(UUID fileId) {
        // 1. Metadata'yƒ± bul
        FileMetadata metadata = repository.findById(fileId)
                .orElseThrow(() -> new RuntimeException("File not found with ID: " + fileId));

        // 2. T√ºm par√ßalarƒ± MinIO'dan sil (Fiziksel Silme)
        for (ShardMetadata shard : metadata.getShards()) {
            // Klas√∂r yapƒ±mƒ±z: fileId/shardIndex (√∂rn: 1f8f.../0)
            String objectName = fileId.toString() + "/" + shard.getShardIndex();

            storageService.deleteShard(
                    shard.getMinioBucketName(),
                    objectName,
                    shard.getShardIndex()
            );
        }

        // 3. Veritabanƒ±ndan kaydƒ± sil (Metadata Silme)
        repository.delete(metadata);
        System.out.println("üóëÔ∏è File " + fileId + " and all its shards have been deleted.");
    }

    public List<FileMetadata> listFiles() {
        return repository.findAll();
    }
}
